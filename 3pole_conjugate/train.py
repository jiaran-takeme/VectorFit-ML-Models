import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm
from torch.utils.data import DataLoader, TensorDataset
import warnings

warnings.filterwarnings('ignore')  # å±è”½æ— å…³è­¦å‘Š


# -------------------------- 1. å·¥å…·å‡½æ•°ï¼šè®¾ç½®ä¸­æ–‡å­—ä½“ --------------------------
def set_chinese_font():
    try:
        fm.fontManager.addfont('C:/Windows/Fonts/simhei.ttf')
        plt.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans']
    except:
        try:
            fm.fontManager.addfont('/Library/Fonts/Songti.ttc')
            plt.rcParams['font.sans-serif'] = ['Songti SC', 'DejaVu Sans']
        except:
            plt.rcParams['font.sans-serif'] = ['DejaVu Sans', 'Arial Unicode MS']
    plt.rcParams['axes.unicode_minus'] = False


set_chinese_font()

# -------------------------- 2. æ•°æ®åŠ è½½ä¸é¢„å¤„ç†ï¼ˆé’ˆå¯¹Trueè¡¨å…±è½­æç‚¹ï¼‰ --------------------------
# è¯»å–Excelæ•°æ®ï¼ˆåˆ‡æ¢ä¸ºTrueå·¥ä½œè¡¨ï¼Œéœ€ç¡®ä¿æ–‡ä»¶è·¯å¾„æ­£ç¡®ï¼‰
try:
    excel_file = pd.ExcelFile('../Data/S21æ‰¹é‡æ‹Ÿåˆæ±‡æ€»ç»“æœ(å«ç›´æµé¡¹å’Œæ¯”ä¾‹é¡¹).xlsx')
    df = excel_file.parse('True')  # è¯»å–å…±è½­æç‚¹çš„Trueå·¥ä½œè¡¨
    print(f"æˆåŠŸè¯»å–Trueè¡¨æ•°æ®ï¼šå…±{len(df)}æ¡æ ·æœ¬ï¼Œ{len(df.columns)}åˆ—ç‰¹å¾")
except FileNotFoundError:
    raise FileNotFoundError("Excelæ–‡ä»¶æœªæ‰¾åˆ°ï¼è¯·æ£€æŸ¥æ–‡ä»¶è·¯å¾„æ˜¯å¦æ­£ç¡®")
except Exception as e:
    raise Exception(f"è¯»å–æ•°æ®å¤±è´¥ï¼š{str(e)}")

# æå–è¾“å…¥ï¼ˆå™¨ä»¶å‚æ•°ï¼‰å’Œå…³é”®è¾“å‡ºï¼ˆä»…éœ€3ä¸ªå‚æ•°ï¼šæç‚¹1å®éƒ¨/è™šéƒ¨ã€æç‚¹3å®éƒ¨ï¼‰
X = df[['Cs', 'Rd', 'Rs']].values  # 3ä¸ªè¾“å…¥ç‰¹å¾ï¼ˆä¸å˜ï¼‰
# å…³é”®è¾“å‡ºï¼šy[:,0]=æç‚¹1å®éƒ¨ï¼Œy[:,1]=æç‚¹1è™šéƒ¨ï¼Œy[:,2]=æç‚¹3å®éƒ¨ï¼ˆæç‚¹3è™šéƒ¨ä¸º0ï¼Œæ— éœ€é¢„æµ‹ï¼‰
y = df[['Pole1_Real', 'Pole1_Imag', 'Pole3_Real']].values
print("æå–å…³é”®è¾“å‡ºå‚æ•°ï¼šæç‚¹1å®éƒ¨ã€æç‚¹1è™šéƒ¨ã€æç‚¹3å®éƒ¨ï¼ˆæç‚¹2ç”±å…±è½­å…³ç³»æ¨å¯¼ï¼‰")

# åˆ’åˆ†è®­ç»ƒé›†ï¼ˆ80%ï¼‰å’Œæµ‹è¯•é›†ï¼ˆ20%ï¼‰
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=16, shuffle=True
)
print(f"æ•°æ®é›†åˆ’åˆ†å®Œæˆï¼šè®­ç»ƒé›†{len(X_train)}æ¡ï¼Œæµ‹è¯•é›†{len(X_test)}æ¡")

# -------------------------- è¾“å‡ºè‡ªåŠ¨åç§»ï¼ˆé’ˆå¯¹å®éƒ¨è´Ÿæ•°å€¼ï¼Œè™šéƒ¨å¯èƒ½æ­£è´Ÿï¼Œä»…åç§»å®éƒ¨ç›¸å…³ï¼‰ --------------------------
# 1. åˆ†æè¾“å‡ºå‚æ•°åˆ†å¸ƒï¼ˆä»…å…³æ³¨å®éƒ¨ï¼šæç‚¹1å®éƒ¨ã€æç‚¹3å®éƒ¨ï¼Œå‡å¯èƒ½ä¸ºè´Ÿï¼‰
pole1_real_min = np.min(y_train[:, 0])  # æç‚¹1å®éƒ¨æœ€å°å€¼
pole3_real_min = np.min(y_train[:, 2])  # æç‚¹3å®éƒ¨æœ€å°å€¼
y_train_real_min = min(pole1_real_min, pole3_real_min)  # å®éƒ¨å…¨å±€æœ€å°å€¼ï¼ˆç”¨äºåç§»ï¼‰
print(f"\nè¾“å‡ºå‚æ•°åˆ†å¸ƒåˆ†æï¼š")
print(f"  - æç‚¹1å®éƒ¨èŒƒå›´ï¼š{pole1_real_min:.6f} ~ {np.max(y_train[:, 0]):.6f}")
print(f"  - æç‚¹1è™šéƒ¨èŒƒå›´ï¼š{np.min(y_train[:, 1]):.6f} ~ {np.max(y_train[:, 1]):.6f}ï¼ˆå…±è½­è™šéƒ¨ï¼‰")
print(f"  - æç‚¹3å®éƒ¨èŒƒå›´ï¼š{pole3_real_min:.6f} ~ {np.max(y_train[:, 2]):.6f}ï¼ˆè™šéƒ¨ä¸º0ï¼‰")

# 2. è‡ªåŠ¨è®¡ç®—åç§»é‡ï¼ˆä»…å¯¹å®éƒ¨å‚æ•°ç”Ÿæ•ˆï¼Œè™šéƒ¨ä¸åç§»ï¼Œé¿å…ç ´åå…±è½­å…³ç³»ï¼‰
output_offset = abs(y_train_real_min) + abs(y_train_real_min) * 0.1  # å®éƒ¨åç§»é‡ï¼ˆé¿å¼€0å€¼ï¼‰
print(f"è‡ªåŠ¨è®¡ç®—å®éƒ¨åç§»é‡={output_offset:.6f}ï¼ˆå®éƒ¨æœ€å°å€¼ç»å¯¹å€¼+10%ä½™é‡ï¼‰")

# 3. è¾“å‡ºåç§»å¤„ç†ï¼ˆä»…åç§»ä¸¤ä¸ªå®éƒ¨å‚æ•°ï¼Œè™šéƒ¨ä¿æŒåŸæ ·ï¼‰
y_train_offset = y_train.copy()
y_test_offset = y_test.copy()
y_train_offset[:, 0] += output_offset  # æç‚¹1å®éƒ¨åç§»ï¼ˆè´Ÿâ†’æ­£ï¼‰
y_train_offset[:, 2] += output_offset  # æç‚¹3å®éƒ¨åç§»ï¼ˆè´Ÿâ†’æ­£ï¼‰
y_test_offset[:, 0] += output_offset  # æµ‹è¯•é›†æç‚¹1å®éƒ¨åç§»
y_test_offset[:, 2] += output_offset  # æµ‹è¯•é›†æç‚¹3å®éƒ¨åç§»
print(f"åç§»åå®éƒ¨èŒƒå›´ï¼š")
print(f"  - æç‚¹1å®éƒ¨ï¼š{np.min(y_train_offset[:, 0]):.6f} ~ {np.max(y_train_offset[:, 0]):.6f}ï¼ˆå‡ä¸ºæ­£ï¼‰")
print(f"  - æç‚¹3å®éƒ¨ï¼š{np.min(y_train_offset[:, 2]):.6f} ~ {np.max(y_train_offset[:, 2]):.6f}ï¼ˆå‡ä¸ºæ­£ï¼‰")

# -------------------------- æ•°æ®æ ‡å‡†åŒ–ï¼ˆè¾“å…¥+åç§»åçš„è¾“å‡ºï¼‰ --------------------------
# è¾“å…¥æ ‡å‡†åŒ–ï¼ˆä¸å˜ï¼‰
scaler_X = StandardScaler()
X_train_scaled = scaler_X.fit_transform(X_train)
X_test_scaled = scaler_X.transform(X_test)

# è¾“å‡ºæ ‡å‡†åŒ–ï¼ˆå®éƒ¨å·²åç§»ï¼Œè™šéƒ¨ç›´æ¥æ ‡å‡†åŒ–ï¼Œä¿æŒå…±è½­ç‰¹æ€§ï¼‰
scaler_y = StandardScaler()
y_train_scaled = scaler_y.fit_transform(y_train_offset)  # æ‹Ÿåˆåç§»åçš„è®­ç»ƒé›†
y_test_scaled = scaler_y.transform(y_test_offset)  # æµ‹è¯•é›†ç”¨è®­ç»ƒé›†å‚æ•°
print("æ•°æ®æ ‡å‡†åŒ–å®Œæˆï¼šè¾“å…¥ç›´æ¥æ ‡å‡†åŒ–ï¼Œè¾“å‡ºå®éƒ¨åç§»åæ ‡å‡†åŒ–ã€è™šéƒ¨ç›´æ¥æ ‡å‡†åŒ–")

# è½¬æ¢ä¸ºPyTorchå¼ é‡å¹¶åˆ›å»ºæ•°æ®åŠ è½½å™¨ï¼ˆæ‰¹é‡å¤§å°64ï¼Œä¿æŒä¸ä½ åŸä»£ç ä¸€è‡´ï¼‰
train_dataset = TensorDataset(torch.FloatTensor(X_train_scaled), torch.FloatTensor(y_train_scaled))
train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, drop_last=False)
X_test_tensor = torch.FloatTensor(X_test_scaled)
y_test_tensor = torch.FloatTensor(y_test_scaled)
print(f"æ•°æ®åŠ è½½å™¨åˆ›å»ºå®Œæˆï¼šæ‰¹é‡å¤§å°{train_loader.batch_size}ï¼Œè®­ç»ƒæ‰¹æ¬¡æ•°{len(train_loader)}")


# -------------------------- 3. å®šä¹‰ç¥ç»ç½‘ç»œæ¨¡å‹ï¼ˆä»ä¸º3è¾“å…¥3è¾“å‡ºï¼‰ --------------------------
class ConjPolePredictor(nn.Module):
    def __init__(self):
        super(ConjPolePredictor, self).__init__()
        self.model = nn.Sequential(
            # è¾“å…¥å±‚â†’éšè—å±‚1ï¼š3â†’256ï¼Œæ‰¹å½’ä¸€åŒ–+ReLU+Dropouté˜²è¿‡æ‹Ÿåˆ
            nn.Linear(3, 256),
            nn.BatchNorm1d(256),
            nn.ReLU(),
            nn.Dropout(0.1),

            # éšè—å±‚1â†’éšè—å±‚2ï¼š256â†’128ï¼Œæ‰¹å½’ä¸€åŒ–+ReLU
            nn.Linear(256, 128),
            nn.BatchNorm1d(128),
            nn.ReLU(),

            # éšè—å±‚2â†’éšè—å±‚3ï¼š128â†’64ï¼Œæ‰¹å½’ä¸€åŒ–+ReLU+Dropout
            nn.Linear(128, 64),
            nn.BatchNorm1d(64),
            nn.ReLU(),
            nn.Dropout(0.1),

            # éšè—å±‚3â†’éšè—å±‚4ï¼š64â†’32ï¼ŒReLU
            nn.Linear(64, 32),
            nn.ReLU(),

            # è¾“å‡ºå±‚ï¼š32â†’3ï¼ˆå¯¹åº”3ä¸ªå…³é”®å‚æ•°ï¼šæç‚¹1å®éƒ¨ã€æç‚¹1è™šéƒ¨ã€æç‚¹3å®éƒ¨ï¼‰
            nn.Linear(32, 3)
        )

    def forward(self, x):
        return self.model(x)


# -------------------------- 4. æ¨¡å‹åˆå§‹åŒ–ä¸è®­ç»ƒé…ç½®ï¼ˆä¸å˜ï¼‰ --------------------------
# åˆå§‹åŒ–æ¨¡å‹ã€æŸå¤±å‡½æ•°ã€ä¼˜åŒ–å™¨
model = ConjPolePredictor()
criterion = nn.MSELoss()  # å›å½’ä»»åŠ¡ç”¨å‡æ–¹è¯¯å·®æŸå¤±
optimizer = optim.Adam(
    model.parameters(),
    lr=0.001,
    weight_decay=1e-5  # L2æ­£åˆ™åŒ–é˜²è¿‡æ‹Ÿåˆ
)
# å­¦ä¹ ç‡è°ƒåº¦å™¨ï¼šæµ‹è¯•æŸå¤±åœæ»10è½®åˆ™é™ä½å­¦ä¹ ç‡ï¼ˆÃ—0.5ï¼‰
scheduler = optim.lr_scheduler.ReduceLROnPlateau(
    optimizer, mode='min', factor=0.5, patience=10, verbose=True
)

# è®­ç»ƒè¶…å‚æ•°ä¸è®°å½•å˜é‡
epochs = 1000
best_test_loss = float('inf')  # åˆå§‹åŒ–æœ€ä½³æµ‹è¯•æŸå¤±ä¸ºæ— ç©·å¤§
train_losses = []  # è®°å½•æ¯è½®è®­ç»ƒæŸå¤±
test_losses = []  # è®°å½•æ¯è½®æµ‹è¯•æŸå¤±
print(f"\nè®­ç»ƒé…ç½®å®Œæˆï¼šæ€»è½®æ¬¡{epochs}ï¼Œåˆå§‹å­¦ä¹ ç‡0.001ï¼Œä¼˜åŒ–å™¨Adamï¼Œå®éƒ¨åç§»é‡{output_offset:.6f}")

# -------------------------- 5. æ¨¡å‹è®­ç»ƒï¼ˆå«æœ€ä½³æ¨¡å‹ä¿å­˜ï¼Œè®°å½•åç§»é‡ï¼‰ --------------------------
print("\n" + "=" * 80)
print("å¼€å§‹è®­ç»ƒï¼ˆæ¯10è½®æ‰“å°æ—¥å¿—ï¼Œæµ‹è¯•æŸå¤±ä¸‹é™æ—¶ä¿å­˜æœ€ä½³æ¨¡å‹ï¼‰")
print("=" * 80)

for epoch in range(epochs):
    # -------------------------- è®­ç»ƒé˜¶æ®µ --------------------------
    model.train()  # åˆ‡æ¢è®­ç»ƒæ¨¡å¼ï¼ˆå¯ç”¨Dropout/BatchNormè®­ç»ƒæ€ï¼‰
    train_loss = 0.0

    for batch_X, batch_y in train_loader:
        optimizer.zero_grad()  # æ¸…ç©ºæ¢¯åº¦
        outputs = model(batch_X)  # å‰å‘ä¼ æ’­ï¼ˆè¾“å‡ºï¼šæç‚¹1å®éƒ¨/è™šéƒ¨ã€æç‚¹3å®éƒ¨ï¼‰
        loss = criterion(outputs, batch_y)  # è®¡ç®—æŸå¤±
        loss.backward()  # åå‘ä¼ æ’­æ±‚æ¢¯åº¦
        optimizer.step()  # æ›´æ–°å‚æ•°
        train_loss += loss.item() * batch_X.size(0)  # ç´¯åŠ æ‰¹æ¬¡æŸå¤±

    # è®¡ç®—å¹³å‡è®­ç»ƒæŸå¤±
    avg_train_loss = train_loss / len(train_loader.dataset)
    train_losses.append(avg_train_loss)

    # -------------------------- éªŒè¯é˜¶æ®µï¼ˆå«æœ€ä½³æ¨¡å‹ä¿å­˜ï¼‰ --------------------------
    model.eval()  # åˆ‡æ¢è¯„ä¼°æ¨¡å¼ï¼ˆç¦ç”¨Dropout/BatchNormå›ºå®šï¼‰
    with torch.no_grad():  # ç¦ç”¨æ¢¯åº¦è®¡ç®—
        outputs = model(X_test_tensor)
        test_loss = criterion(outputs, y_test_tensor).item()
        test_losses.append(test_loss)

        # ä»…å½“æµ‹è¯•æŸå¤±ä¸‹é™æ—¶ï¼Œä¿å­˜æœ€ä½³æ¨¡å‹åŠè®­ç»ƒä¿¡æ¯
        if test_loss < best_test_loss:
            best_test_loss = test_loss  # æ›´æ–°æœ€ä½³æŸå¤±
            # 1. ä¿å­˜æ¨¡å‹å‚æ•°
            torch.save(model.state_dict(), 'best_conj_pole_predictor.pth')
            # 2. ä¿å­˜è®­ç»ƒä¿¡æ¯ï¼ˆå«åç§»é‡ã€æ ‡å‡†åŒ–å‚æ•°ï¼Œä¾¿äºåç»­é¢„æµ‹ï¼‰
            best_model_info = {
                'epoch': epoch + 1,
                'train_loss': avg_train_loss,
                'test_loss': test_loss,
                'output_offset': output_offset,  # å®éƒ¨åç§»é‡ï¼ˆåæ ‡å‡†åŒ–éœ€å¤ç”¨ï¼‰
                'scaler_X': {'mean': scaler_X.mean_.tolist(), 'std': scaler_X.scale_.tolist()},
                'scaler_y': {'mean': scaler_y.mean_.tolist(), 'std': scaler_y.scale_.tolist()},
                'batch_size': train_loader.batch_size,
                'lr': optimizer.param_groups[0]['lr']
            }
            np.save('best_conj_model_info.npy', best_model_info)
            # 3. æ‰“å°ä¿å­˜æ—¥å¿—
            print(f"Epoch {epoch + 1:4d}: æµ‹è¯•æŸå¤±{test_loss:.6f}ï¼ˆå†å²æœ€ä½³ï¼‰â†’ ä¿å­˜æ¨¡å‹")

    # å­¦ä¹ ç‡è°ƒåº¦
    scheduler.step(test_loss)

    # æ¯10è½®æ‰“å°è®­ç»ƒæ—¥å¿—
    if (epoch + 1) % 10 == 0:
        current_lr = optimizer.param_groups[0]['lr']
        print(
            f"Epoch [{epoch + 1:4d}/{epochs}] | è®­ç»ƒæŸå¤±: {avg_train_loss:.6f} | æµ‹è¯•æŸå¤±: {test_loss:.6f} | å½“å‰å­¦ä¹ ç‡: {current_lr:.8f}")

# -------------------------- 6. åŠ è½½æœ€ä½³æ¨¡å‹å¹¶è¯„ä¼°ï¼ˆæ¨å¯¼å®Œæ•´3ä¸ªæç‚¹ï¼‰ --------------------------
print("\n" + "=" * 80)
print("è®­ç»ƒç»“æŸï¼ŒåŠ è½½æœ€ä½³æ¨¡å‹è¯„ä¼°ï¼ˆè‡ªåŠ¨æ¨å¯¼æç‚¹2ï¼‰")
print("=" * 80)

# åŠ è½½æœ€ä½³æ¨¡å‹ï¼ˆå«å¼‚å¸¸å¤„ç†ï¼Œå¤ç”¨åç§»é‡ï¼‰
output_offset_loaded = output_offset  # é»˜è®¤ç”¨å½“å‰åç§»é‡
try:
    # åŠ è½½æ¨¡å‹å‚æ•°
    model.load_state_dict(torch.load('best_conj_pole_predictor.pth'))
    # åŠ è½½è®­ç»ƒä¿¡æ¯ï¼ˆå«åç§»é‡ã€æ ‡å‡†åŒ–å‚æ•°ï¼‰
    best_info = np.load('best_conj_model_info.npy', allow_pickle=True).item()
    output_offset_loaded = best_info['output_offset']  # å¤ç”¨è®­ç»ƒæ—¶çš„å®éƒ¨åç§»é‡
    print(f"âœ… æˆåŠŸåŠ è½½æœ€ä½³æ¨¡å‹ï¼š")
    print(f"   - å¯¹åº”è®­ç»ƒè½®æ¬¡ï¼šEpoch {best_info['epoch']}")
    print(f"   - æœ€ä½³æµ‹è¯•æŸå¤±ï¼š{best_info['test_loss']:.6f}")
    print(f"   - å¤ç”¨å®éƒ¨åç§»é‡ï¼š{output_offset_loaded:.6f}")
    print(f"   - æ ‡å‡†åŒ–å™¨å‚æ•°å·²åŒæ­¥åŠ è½½")
except FileNotFoundError:
    print("âš ï¸ è­¦å‘Šï¼šæœªæ‰¾åˆ°æœ€ä½³æ¨¡å‹æ–‡ä»¶ï¼Œä½¿ç”¨æœ€åä¸€è½®æ¨¡å‹è¯„ä¼°")
except Exception as e:
    print(f"âŒ åŠ è½½æ¨¡å‹å¤±è´¥ï¼š{str(e)}ï¼Œä½¿ç”¨å½“å‰è®¡ç®—çš„åç§»é‡{output_offset_loaded:.6f}")
model.eval()  # å›ºå®šè¯„ä¼°æ¨¡å¼

# åœ¨æµ‹è¯•é›†ä¸Šé¢„æµ‹å¹¶åæ ‡å‡†åŒ–ï¼ˆæ¢å¤åŸå§‹å°ºåº¦ï¼‰
with torch.no_grad():
    # 1. æ¨¡å‹é¢„æµ‹å…³é”®å‚æ•°ï¼ˆæ ‡å‡†åŒ–åï¼‰
    y_pred_scaled = model(X_test_tensor)
    # 2. åæ ‡å‡†åŒ–ï¼šæ¢å¤åˆ°åç§»åçš„å°ºåº¦
    y_pred_offset = scaler_y.inverse_transform(y_pred_scaled.numpy())
    y_true_offset = scaler_y.inverse_transform(y_test_scaled)

    # 3. ååç§»ï¼šä»…å®éƒ¨å‚æ•°å‡å»åç§»é‡ï¼Œæ¢å¤åŸå§‹è´Ÿå€¼
    y_pred = y_pred_offset.copy()
    y_true = y_true_offset.copy()
    y_pred[:, 0] -= output_offset_loaded  # æç‚¹1å®éƒ¨ååç§»
    y_pred[:, 2] -= output_offset_loaded  # æç‚¹3å®éƒ¨ååç§»
    y_true[:, 0] -= output_offset_loaded  # çœŸå®æç‚¹1å®éƒ¨ååç§»
    y_true[:, 2] -= output_offset_loaded  # çœŸå®æç‚¹3å®éƒ¨ååç§»


# -------------------------- æ¨å¯¼å®Œæ•´3ä¸ªæç‚¹ï¼ˆæ ¸å¿ƒï¼šå…±è½­å…³ç³»ç”Ÿæˆæç‚¹2ï¼‰ --------------------------
def get_complete_poles(pred_key_params, true_key_params):
    """
    ç”±å…³é”®å‚æ•°ç”Ÿæˆå®Œæ•´3ä¸ªæç‚¹
    pred_key_params: æ¨¡å‹é¢„æµ‹çš„å…³é”®å‚æ•°ï¼ˆn_samples, 3ï¼‰ï¼š[pole1_real, pole1_imag, pole3_real]
    true_key_params: çœŸå®å…³é”®å‚æ•°ï¼ˆn_samples, 3ï¼‰
    return: å®Œæ•´é¢„æµ‹æç‚¹ã€å®Œæ•´çœŸå®æç‚¹ï¼ˆn_samples, 3, 2ï¼‰ï¼š[å®éƒ¨, è™šéƒ¨]
    """
    n_samples = len(pred_key_params)
    # åˆå§‹åŒ–å®Œæ•´æç‚¹æ•°ç»„ï¼ˆæ¯ä¸ªæç‚¹å­˜[å®éƒ¨, è™šéƒ¨]ï¼‰
    pred_poles = np.zeros((n_samples, 3, 2))  # pred_poles[i,0] = æç‚¹1ï¼Œi,1=æç‚¹2ï¼Œi,2=æç‚¹3
    true_poles = np.zeros((n_samples, 3, 2))

    # å¡«å……æç‚¹1ï¼ˆé¢„æµ‹+çœŸå®ï¼‰
    pred_poles[:, 0, 0] = pred_key_params[:, 0]  # æç‚¹1å®éƒ¨
    pred_poles[:, 0, 1] = pred_key_params[:, 1]  # æç‚¹1è™šéƒ¨
    true_poles[:, 0, 0] = true_key_params[:, 0]  # çœŸå®æç‚¹1å®éƒ¨
    true_poles[:, 0, 1] = true_key_params[:, 1]  # çœŸå®æç‚¹1è™šéƒ¨

    # ç”Ÿæˆæç‚¹2ï¼ˆå…±è½­å…³ç³»ï¼šå®éƒ¨ç›¸åŒï¼Œè™šéƒ¨ç›¸åï¼‰
    pred_poles[:, 1, 0] = pred_poles[:, 0, 0]  # æç‚¹2å®éƒ¨ = æç‚¹1å®éƒ¨
    pred_poles[:, 1, 1] = -pred_poles[:, 0, 1]  # æç‚¹2è™šéƒ¨ = -æç‚¹1è™šéƒ¨
    true_poles[:, 1, 0] = true_poles[:, 0, 0]  # çœŸå®æç‚¹2å®éƒ¨ = çœŸå®æç‚¹1å®éƒ¨
    true_poles[:, 1, 1] = -true_poles[:, 0, 1]  # çœŸå®æç‚¹2è™šéƒ¨ = -çœŸå®æç‚¹1è™šéƒ¨

    # å¡«å……æç‚¹3ï¼ˆè™šéƒ¨ä¸º0ï¼‰
    pred_poles[:, 2, 0] = pred_key_params[:, 2]  # æç‚¹3å®éƒ¨
    pred_poles[:, 2, 1] = 0.0  # æç‚¹3è™šéƒ¨=0ï¼ˆå·²çŸ¥ï¼‰
    true_poles[:, 2, 0] = true_key_params[:, 2]  # çœŸå®æç‚¹3å®éƒ¨
    true_poles[:, 2, 1] = 0.0  # çœŸå®æç‚¹3è™šéƒ¨=0

    return pred_poles, true_poles


# ç”Ÿæˆå®Œæ•´çš„é¢„æµ‹æç‚¹å’ŒçœŸå®æç‚¹
pred_poles, true_poles = get_complete_poles(y_pred, y_true)
print(f"\nâœ… å·²é€šè¿‡å…±è½­å…³ç³»ç”Ÿæˆå®Œæ•´3ä¸ªæç‚¹ï¼š")
print(f"  - æç‚¹2ï¼šå®éƒ¨=æç‚¹1å®éƒ¨ï¼Œè™šéƒ¨=-æç‚¹1è™šéƒ¨ï¼ˆå…±è½­ï¼‰")
print(f"  - æç‚¹3ï¼šè™šéƒ¨=0ï¼ˆå·²çŸ¥ï¼Œä»…é¢„æµ‹å®éƒ¨ï¼‰")


# -------------------------- 7. è®¡ç®—è¯„ä¼°æŒ‡æ ‡ï¼ˆæŒ‰å®Œæ•´æç‚¹è®¡ç®—è¯¯å·®ï¼‰ --------------------------
# è®¡ç®—æ¯ä¸ªæç‚¹çš„å®éƒ¨/è™šéƒ¨å¹³å‡ç»å¯¹è¯¯å·®ï¼ˆMAEï¼‰
def calculate_pole_mae(pred_poles, true_poles):
    """è®¡ç®—æ¯ä¸ªæç‚¹çš„å®éƒ¨MAEå’Œè™šéƒ¨MAE"""
    mae_dict = {}
    for i in range(3):
        pole_name = f"æç‚¹{i + 1}"
        # å®éƒ¨MAE
        mae_real = np.mean(np.abs(pred_poles[:, i, 0] - true_poles[:, i, 0]))
        # è™šéƒ¨MAEï¼ˆæç‚¹3è™šéƒ¨æ’ä¸º0ï¼Œè¯¯å·®ä»…æ¥è‡ªé¢„æµ‹ç¨³å®šæ€§ï¼‰
        mae_imag = np.mean(np.abs(pred_poles[:, i, 1] - true_poles[:, i, 1]))
        mae_dict[pole_name] = {'å®éƒ¨MAE': mae_real, 'è™šéƒ¨MAE': mae_imag}
    return mae_dict


pole_mae = calculate_pole_mae(pred_poles, true_poles)
total_mae = (
                    pole_mae['æç‚¹1']['å®éƒ¨MAE'] + pole_mae['æç‚¹1']['è™šéƒ¨MAE'] +
                    pole_mae['æç‚¹2']['å®éƒ¨MAE'] + pole_mae['æç‚¹2']['è™šéƒ¨MAE'] +
                    pole_mae['æç‚¹3']['å®éƒ¨MAE'] + pole_mae['æç‚¹3']['è™šéƒ¨MAE']
            ) / 6  # æ€»å¹³å‡è¯¯å·®

print(f"\nğŸ“Š æ¨¡å‹è¯„ä¼°ç»“æœï¼ˆå¹³å‡ç»å¯¹è¯¯å·®MAEï¼‰ï¼š")
for pole, mae in pole_mae.items():
    if pole == 'æç‚¹2':
        print(f"   - {pole}ï¼ˆå…±è½­æ¨å¯¼ï¼‰ï¼šå®éƒ¨MAE={mae['å®éƒ¨MAE']:.4f}ï¼Œè™šéƒ¨MAE={mae['è™šéƒ¨MAE']:.4f}")
    elif pole == 'æç‚¹3':
        print(f"   - {pole}ï¼ˆè™šéƒ¨=0ï¼‰ï¼šå®éƒ¨MAE={mae['å®éƒ¨MAE']:.4f}ï¼Œè™šéƒ¨MAE={mae['è™šéƒ¨MAE']:.4f}")
    else:
        print(f"   - {pole}ï¼ˆæ¨¡å‹é¢„æµ‹ï¼‰ï¼šå®éƒ¨MAE={mae['å®éƒ¨MAE']:.4f}ï¼Œè™šéƒ¨MAE={mae['è™šéƒ¨MAE']:.4f}")
print(f"   - æ€»å¹³å‡è¯¯å·®ï¼š{total_mae:.4f}")

# -------------------------- 8. å¯è§†åŒ–ç»“æœï¼ˆå®Œæ•´æç‚¹å¯¹æ¯”ï¼‰ --------------------------
# 8.1 ç»˜åˆ¶è®­ç»ƒ/æµ‹è¯•æŸå¤±æ›²çº¿
plt.figure(figsize=(10, 6))
plt.plot(range(1, epochs + 1), train_losses, color='#2E86AB', linewidth=1.5, label='è®­ç»ƒæŸå¤±')
plt.plot(range(1, epochs + 1), test_losses, color='#A23B72', linewidth=1.5, label='æµ‹è¯•æŸå¤±')
# æ ‡æ³¨æœ€ä½³æ¨¡å‹å¯¹åº”çš„epoch
if 'best_info' in locals():
    best_epoch = best_info['epoch']
    best_loss = best_info['test_loss']
    plt.scatter(best_epoch, best_loss, color='red', s=50, zorder=5, label=f'æœ€ä½³æ¨¡å‹ï¼ˆEpoch{best_epoch}ï¼‰')
plt.xlabel('è®­ç»ƒè½®æ¬¡ï¼ˆEpochï¼‰', fontsize=11)
plt.ylabel('æŸå¤±å€¼ï¼ˆMSEï¼‰', fontsize=11)
plt.title('è®­ç»ƒä¸æµ‹è¯•æŸå¤±æ›²çº¿ï¼ˆTrueè¡¨ï¼šå…±è½­æç‚¹ï¼‰', fontsize=13, pad=15)
plt.legend(fontsize=10)
plt.grid(True, linestyle='--', alpha=0.7)
plt.tight_layout()
plt.savefig('conj_loss_curve.png', dpi=300, bbox_inches='tight')
plt.close()
print(f"\nğŸ“ˆ æŸå¤±æ›²çº¿å·²ä¿å­˜ä¸ºï¼šconj_loss_curve.png")

# 8.2 ç»˜åˆ¶å‰50ä¸ªæ ·æœ¬çš„å®Œæ•´æç‚¹å¯¹æ¯”ï¼ˆåˆ†å®éƒ¨/è™šéƒ¨ï¼‰
sample_num = min(50, len(pred_poles))
sample_indices = np.arange(sample_num)
fig, axes = plt.subplots(3, 2, figsize=(14, 15), sharex=True)  # 3ä¸ªæç‚¹Ã—2ï¼ˆå®éƒ¨/è™šéƒ¨ï¼‰

for i in range(3):
    pole_name = f"æç‚¹{i + 1}"
    # å®éƒ¨å¯¹æ¯”ï¼ˆç¬¬0åˆ—å­å›¾ï¼‰
    axes[i, 0].plot(sample_indices, true_poles[sample_indices, i, 0], color='#2E86AB', linewidth=2, label='çœŸå®å®éƒ¨')
    axes[i, 0].plot(sample_indices, pred_poles[sample_indices, i, 0], color='#FF0000', linewidth=1.5, linestyle='--',
                    label='é¢„æµ‹å®éƒ¨')
    axes[i, 0].set_title(f'{pole_name} å®éƒ¨å¯¹æ¯”ï¼ˆå‰{sample_num}ä¸ªæ ·æœ¬ï¼‰', fontsize=12, pad=12)
    axes[i, 0].set_ylabel('å®éƒ¨å€¼', fontsize=10)
    axes[i, 0].legend(fontsize=9)
    axes[i, 0].grid(True, linestyle='--', alpha=0.3)

    # è™šéƒ¨å¯¹æ¯”ï¼ˆç¬¬1åˆ—å­å›¾ï¼‰
    axes[i, 1].plot(sample_indices, true_poles[sample_indices, i, 1], color='#2E86AB', linewidth=2, label='çœŸå®è™šéƒ¨')
    axes[i, 1].plot(sample_indices, pred_poles[sample_indices, i, 1], color='#FF0000', linewidth=1.5, linestyle='--',
                    label='é¢„æµ‹è™šéƒ¨')
    # æ ‡æ³¨å…±è½­/å›ºå®šè™šéƒ¨è¯´æ˜
    if i == 1:
        axes[i, 1].set_title(f'{pole_name} è™šéƒ¨å¯¹æ¯”ï¼ˆå…±è½­æ¨å¯¼ï¼š-æç‚¹1è™šéƒ¨ï¼‰', fontsize=12, pad=12)
    elif i == 2:
        axes[i, 1].set_title(f'{pole_name} è™šéƒ¨å¯¹æ¯”ï¼ˆå›ºå®šä¸º0ï¼‰', fontsize=12, pad=12)
    else:
        axes[i, 1].set_title(f'{pole_name} è™šéƒ¨å¯¹æ¯”ï¼ˆæ¨¡å‹é¢„æµ‹ï¼‰', fontsize=12, pad=12)
    axes[i, 1].set_ylabel('è™šéƒ¨å€¼', fontsize=10)
    axes[i, 1].legend(fontsize=9)
    axes[i, 1].grid(True, linestyle='--', alpha=0.3)

axes[-1, 0].set_xlabel('æ ·æœ¬ç´¢å¼•', fontsize=10)
axes[-1, 1].set_xlabel('æ ·æœ¬ç´¢å¼•', fontsize=10)
plt.tight_layout()
plt.savefig('conj_pole_comparison.png', dpi=300, bbox_inches='tight')
plt.close()
print(f"ğŸ“Š å…±è½­æç‚¹å¯¹æ¯”å›¾å·²ä¿å­˜ä¸ºï¼šconj_pole_comparison.png")

# -------------------------- 9. æ‰“å°å‰10æ¡å®Œæ•´é¢„æµ‹ç»“æœæ˜ç»† --------------------------
print("\n" + "=" * 120)
print("å‰10æ¡æ ·æœ¬å®Œæ•´é¢„æµ‹ç»“æœæ˜ç»†ï¼ˆTrueè¡¨ï¼šå…±è½­æç‚¹ï¼‰")
print("=" * 120)
print(
    f"{'æ ·æœ¬':<6} {'æç‚¹1å®éƒ¨(çœŸ)':<12} {'æç‚¹1å®éƒ¨(é¢„)':<12} {'æç‚¹1è™šéƒ¨(çœŸ)':<12} {'æç‚¹1è™šéƒ¨(é¢„)':<12} "
    f"{'æç‚¹2è™šéƒ¨(çœŸ)':<12} {'æç‚¹2è™šéƒ¨(é¢„)':<12} {'æç‚¹3å®éƒ¨(çœŸ)':<12} {'æç‚¹3å®éƒ¨(é¢„)':<12}"
)
print("-" * 120)
for i in range(min(10, len(pred_poles))):
    print(
        f"{i:<6} {true_poles[i, 0, 0]:<12.4f} {pred_poles[i, 0, 0]:<12.4f} {true_poles[i, 0, 1]:<12.4f} {pred_poles[i, 0, 1]:<12.4f} "
        f"{true_poles[i, 1, 1]:<12.4f} {pred_poles[i, 1, 1]:<12.4f} {true_poles[i, 2, 0]:<12.4f} {pred_poles[i, 2, 0]:<12.4f}"
    )

print("\n" + "=" * 80)
print("æ‰€æœ‰æ–‡ä»¶å·²ä¿å­˜è‡³å½“å‰ç›®å½•ï¼š")
print("1. best_conj_pole_predictor.pth â†’ å…±è½­æç‚¹æœ€ä½³æ¨¡å‹å‚æ•°æ–‡ä»¶")
print("2. best_conj_model_info.npy â†’ æ¨¡å‹è®­ç»ƒä¿¡æ¯ï¼ˆå«åç§»é‡+æ ‡å‡†åŒ–å‚æ•°ï¼‰")
print("3. conj_loss_curve.png â†’ è®­ç»ƒ/æµ‹è¯•æŸå¤±æ›²çº¿")
print("4. conj_pole_comparison.png â†’ å…±è½­æç‚¹é¢„æµ‹å¯¹æ¯”å›¾")
print("=" * 80)