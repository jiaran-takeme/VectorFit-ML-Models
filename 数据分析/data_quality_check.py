import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm
from torch.utils.data import DataLoader, TensorDataset
import warnings

warnings.filterwarnings('ignore')  # å±è”½æ— å…³è­¦å‘Š


# -------------------------- 1. å·¥å…·å‡½æ•°ï¼šè®¾ç½®ä¸­æ–‡å­—ä½“ï¼ˆå¾®è½¯é›…é»‘ä¼˜å…ˆï¼‰ --------------------------
def set_chinese_font():
    try:
        # ä¼˜å…ˆåŠ è½½å¾®è½¯é›…é»‘ï¼ˆå¯¹æ•°å­¦ç¬¦å·å’Œå°å­—ä½“æ”¯æŒæ›´å¥½ï¼‰
        fm.fontManager.addfont('C:/Windows/Fonts/msyh.ttc')
        plt.rcParams['font.sans-serif'] = ['Microsoft YaHei', 'DejaVu Sans']
    except:
        try:
            # å¤‡ç”¨ï¼šåŠ è½½é»‘ä½“
            fm.fontManager.addfont('C:/Windows/Fonts/simhei.ttf')
            plt.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans']
        except:
            # å…œåº•ï¼šä½¿ç”¨ç³»ç»Ÿé»˜è®¤æ”¯æŒå­—ä½“
            plt.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'DejaVu Sans']
    plt.rcParams['axes.unicode_minus'] = False  # è§£å†³è´Ÿå·æ˜¾ç¤ºå¼‚å¸¸é—®é¢˜


set_chinese_font()

# -------------------------- 2. æ•°æ®åŠ è½½ä¸é¢„å¤„ç†ï¼ˆCsä¼˜åŒ–+æç‚¹ç•™æ•°ä¸€ä¸€å¯¹åº”è¾“å‡ºï¼‰ --------------------------
# è¯»å–Excelæ•°æ®ï¼ˆéœ€ç¡®ä¿æ–‡ä»¶è·¯å¾„æ­£ç¡®ï¼‰
try:
    excel_file = pd.ExcelFile('../S21æ‰¹é‡æ‹Ÿåˆæ±‡æ€»ç»“æœ(å«ç›´æµé¡¹å’Œæ¯”ä¾‹é¡¹)new.xlsx')
    df = excel_file.parse('False')  # è¯»å–éå…±è½­æ•°æ®ï¼ˆä»…å®éƒ¨ï¼‰
    print(f"æˆåŠŸè¯»å–æ•°æ®ï¼šå…±{len(df)}æ¡æ ·æœ¬ï¼Œ{len(df.columns)}åˆ—ç‰¹å¾")
except FileNotFoundError:
    raise FileNotFoundError("Excelæ–‡ä»¶æœªæ‰¾åˆ°ï¼è¯·æ£€æŸ¥æ–‡ä»¶è·¯å¾„æ˜¯å¦æ­£ç¡®")
except Exception as e:
    raise Exception(f"è¯»å–æ•°æ®å¤±è´¥ï¼š{str(e)}")

# -------------------------- Csé¢„å¤„ç†ä¸ç‰¹å¾å·¥ç¨‹ï¼ˆæ”¾å¤§å°å°ºåº¦å·®å¼‚ï¼‰ --------------------------
# 1. Cså¯¹æ•°å˜æ¢ï¼ˆè§£å†³1e-14é‡çº§å°ºåº¦å‹åˆ¶é—®é¢˜ï¼‰
df['Cs_log'] = np.log10(df['Cs'] + 1e-16)  # +1e-16é¿å…log(0)
# 2. æ„é€ ç‰©ç†æ„ä¹‰äº¤äº’ç‰¹å¾ï¼ˆå¢å¼ºä¸æç‚¹/ç•™æ•°çš„å…³è”ï¼‰
df['Cs_Rd'] = df['Cs'] * df['Rd']  # ç”µå®¹-ç”µé˜»æ—¶é—´å¸¸æ•°ï¼ˆRCï¼‰
df['Cs_Rs'] = df['Cs'] * df['Rs']  # ä¸²è”RCé¡¹
df['Rd_over_Rs'] = df['Rd'] / (df['Rs'] + 1e-8)  # ç”µé˜»æ¯”å€¼ï¼ˆé˜²é™¤é›¶ï¼‰

# æå–è¾“å…¥ç‰¹å¾ï¼ˆ6ç»´ï¼šåŸå§‹Cs+å˜æ¢ç‰¹å¾+äº¤äº’ç‰¹å¾ï¼‰
input_cols = ['Cs', 'Cs_log', 'Rd', 'Rs', 'Cs_Rd', 'Rd_over_Rs']
X = df[input_cols].values
print(f"è¾“å…¥ç‰¹å¾ï¼š{input_cols}ï¼ˆå…±{len(input_cols)}ç»´ï¼Œå·²ä¼˜åŒ–Cså°ºåº¦ï¼‰")

# -------------------------- è¾“å‡ºè®¾ç½®ï¼šæç‚¹1-3 + ç•™æ•°1-3ï¼ˆä¸€ä¸€å¯¹åº”ï¼Œä¸æ’åºï¼‰ --------------------------
# æŒ‰åŸå§‹é¡ºåºæå–ï¼Œç¡®ä¿æç‚¹iä¸ç•™æ•°iå¯¹åº”ï¼ˆç¬¦åˆå‘é‡æ‹Ÿåˆé…å¯¹å…³ç³»ï¼‰
output_cols = ['Pole1_Real', 'Pole2_Real', 'Pole3_Real',
               'Residue1_Real', 'Residue2_Real', 'Residue3_Real']
y = df[output_cols].values
print(f"è¾“å‡ºç‰¹å¾ï¼š{output_cols}ï¼ˆå…±{len(output_cols)}ç»´ï¼Œæç‚¹-ç•™æ•°ä¸€ä¸€å¯¹åº”ï¼‰")

# åˆ’åˆ†è®­ç»ƒé›†ï¼ˆ80%ï¼‰å’Œæµ‹è¯•é›†ï¼ˆ20%ï¼‰
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=16, shuffle=True
)
print(f"æ•°æ®é›†åˆ’åˆ†å®Œæˆï¼šè®­ç»ƒé›†{len(X_train)}æ¡ï¼Œæµ‹è¯•é›†{len(X_test)}æ¡")

# -------------------------- è¾“å‡ºåç§»å¤„ç†ï¼ˆä»…å¯¹è´Ÿæç‚¹ï¼Œç•™æ•°ä¸åç§»ï¼‰ --------------------------
# åˆ†ç¦»è¾“å‡ºä¸­çš„â€œæç‚¹â€ï¼ˆå‰3åˆ—ï¼Œå‡ä¸ºè´Ÿï¼‰å’Œâ€œç•™æ•°â€ï¼ˆå3åˆ—ï¼Œæ­£è´Ÿä¸å®šï¼‰
y_train_poles = y_train[:, :3]  # è®­ç»ƒé›†æç‚¹1-3
y_train_residues = y_train[:, 3:]  # è®­ç»ƒé›†ç•™æ•°1-3
y_test_poles = y_test[:, :3]  # æµ‹è¯•é›†æç‚¹1-3
y_test_residues = y_test[:, 3:]  # æµ‹è¯•é›†ç•™æ•°1-3

# è®¡ç®—æç‚¹åç§»é‡ï¼ˆä»…ç”¨è®­ç»ƒé›†ï¼Œé¿å…æ•°æ®æ³„éœ²ï¼‰
y_train_pole_min = np.min(y_train_poles)
output_offset = abs(y_train_pole_min) + abs(y_train_pole_min) * 0.1  # åŠ 10%ä½™é‡é˜²é›¶
print(f"\næç‚¹åˆ†å¸ƒï¼šè®­ç»ƒé›†æœ€å°å€¼={y_train_pole_min:.6f}ï¼ˆå‡ä¸ºè´Ÿï¼‰ï¼Œåç§»é‡={output_offset:.6f}")

# ä»…å¯¹æç‚¹æ‰§è¡Œåç§»ï¼ˆç•™æ•°ä¿æŒåŸå§‹å€¼ï¼Œé¿å…ç ´åç‰©ç†æ„ä¹‰ï¼‰
y_train_poles_offset = y_train_poles + output_offset
y_test_poles_offset = y_test_poles + output_offset
print(f"åç§»åè®­ç»ƒé›†æç‚¹èŒƒå›´ï¼š{np.min(y_train_poles_offset):.6f} ~ {np.max(y_train_poles_offset):.6f}ï¼ˆå‡ä¸ºæ­£ï¼‰")

# åˆå¹¶åç§»æç‚¹å’ŒåŸå§‹ç•™æ•°ï¼Œä½œä¸ºæœ€ç»ˆè®­ç»ƒè¾“å‡º
y_train_final = np.hstack([y_train_poles_offset, y_train_residues])
y_test_final = np.hstack([y_test_poles_offset, y_test_residues])

# -------------------------- æ•°æ®æ ‡å‡†åŒ–ï¼ˆè¾“å…¥+è¾“å‡ºï¼‰ --------------------------
# è¾“å…¥æ ‡å‡†åŒ–
scaler_X = StandardScaler()
X_train_scaled = scaler_X.fit_transform(X_train)
X_test_scaled = scaler_X.transform(X_test)

# è¾“å‡ºæ ‡å‡†åŒ–ï¼ˆåç§»æç‚¹+åŸå§‹ç•™æ•°æ•´ä½“æ ‡å‡†åŒ–ï¼‰
scaler_y = StandardScaler()
y_train_scaled = scaler_y.fit_transform(y_train_final)
y_test_scaled = scaler_y.transform(y_test_final)
print("æ•°æ®æ ‡å‡†åŒ–å®Œæˆï¼šè¾“å…¥6ç»´ç‰¹å¾ï¼Œè¾“å‡º6ç»´ï¼ˆåç§»æç‚¹+åŸå§‹ç•™æ•°ï¼‰")

# è½¬æ¢ä¸ºPyTorchå¼ é‡å¹¶åˆ›å»ºæ•°æ®åŠ è½½å™¨
train_dataset = TensorDataset(torch.FloatTensor(X_train_scaled), torch.FloatTensor(y_train_scaled))
train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, drop_last=False)
X_test_tensor = torch.FloatTensor(X_test_scaled)
y_test_tensor = torch.FloatTensor(y_test_scaled)
print(f"æ•°æ®åŠ è½½å™¨ï¼šæ‰¹é‡å¤§å°{train_loader.batch_size}ï¼Œè®­ç»ƒæ‰¹æ¬¡æ•°{len(train_loader)}")


# -------------------------- 3. å®šä¹‰ç¥ç»ç½‘ç»œæ¨¡å‹ï¼ˆè¾“å‡º6ç»´ï¼š3æç‚¹+3ç•™æ•°ï¼‰ --------------------------
class PoleResiduePredictor(nn.Module):
    def __init__(self):
        super(PoleResiduePredictor, self).__init__()
        self.model = nn.Sequential(
            # è¾“å…¥å±‚â†’éšè—å±‚1ï¼š6ç»´â†’256ç»´ï¼ˆå……åˆ†æå–ç‰¹å¾ï¼‰
            nn.Linear(6, 256),
            nn.BatchNorm1d(256),
            nn.ReLU(),
            nn.Dropout(0.1),

            # éšè—å±‚1â†’éšè—å±‚2ï¼š256â†’128ï¼ˆé€æ­¥å‹ç¼©ï¼‰
            nn.Linear(256, 128),
            nn.BatchNorm1d(128),
            nn.ReLU(),

            # éšè—å±‚2â†’éšè—å±‚3ï¼š128â†’64ï¼ˆè¿›ä¸€æ­¥å‹ç¼©ï¼‰
            nn.Linear(128, 64),
            nn.BatchNorm1d(64),
            nn.ReLU(),
            nn.Dropout(0.1),

            # éšè—å±‚3â†’éšè—å±‚4ï¼š64â†’32ï¼ˆæ¥è¿‘è¾“å‡ºç»´åº¦ï¼‰
            nn.Linear(64, 32),
            nn.ReLU(),

            # è¾“å‡ºå±‚ï¼š32â†’6ï¼ˆæç‚¹1-3åç§»å + ç•™æ•°1-3åŸå§‹ï¼Œä¸€ä¸€å¯¹åº”ï¼‰
            nn.Linear(32, 6)
        )

    def forward(self, x):
        return self.model(x)


# -------------------------- 4. æ¨¡å‹åˆå§‹åŒ–ä¸è®­ç»ƒé…ç½® --------------------------
model = PoleResiduePredictor()
criterion = nn.MSELoss()  # å›å½’ä»»åŠ¡ç”¨å‡æ–¹è¯¯å·®æŸå¤±
optimizer = optim.Adam(
    model.parameters(),
    lr=0.001,
    weight_decay=1e-5  # L2æ­£åˆ™åŒ–é˜²è¿‡æ‹Ÿåˆ
)
# å­¦ä¹ ç‡è°ƒåº¦å™¨ï¼šæµ‹è¯•æŸå¤±åœæ»10è½®é™ä¸º50%
scheduler = optim.lr_scheduler.ReduceLROnPlateau(
    optimizer, mode='min', factor=0.5, patience=10, verbose=True
)

# è®­ç»ƒè¶…å‚æ•°
epochs = 1000
best_test_loss = float('inf')
train_losses = []  # è®­ç»ƒæŸå¤±è®°å½•
test_losses = []  # æµ‹è¯•æŸå¤±è®°å½•
print(f"\nè®­ç»ƒé…ç½®ï¼šæ€»è½®æ¬¡{epochs}ï¼Œåˆå§‹å­¦ä¹ ç‡0.001ï¼Œä¼˜åŒ–å™¨Adamï¼Œæç‚¹åç§»é‡{output_offset:.6f}")

# -------------------------- 5. æ¨¡å‹è®­ç»ƒï¼ˆå«æœ€ä½³æ¨¡å‹ä¿å­˜ï¼‰ --------------------------
print("\n" + "=" * 80)
print("å¼€å§‹è®­ç»ƒï¼ˆæ¯10è½®æ‰“å°æ—¥å¿—ï¼Œæµ‹è¯•æŸå¤±ä¸‹é™æ—¶ä¿å­˜æ¨¡å‹ï¼‰")
print("=" * 80)

for epoch in range(epochs):
    # -------------------------- è®­ç»ƒé˜¶æ®µ --------------------------
    model.train()
    train_loss = 0.0
    for batch_X, batch_y in train_loader:
        optimizer.zero_grad()  # æ¸…ç©ºæ¢¯åº¦
        outputs = model(batch_X)  # å‰å‘ä¼ æ’­
        loss = criterion(outputs, batch_y)  # è®¡ç®—æŸå¤±
        loss.backward()  # åå‘ä¼ æ’­
        optimizer.step()  # æ›´æ–°å‚æ•°
        train_loss += loss.item() * batch_X.size(0)  # ç´¯åŠ æ‰¹æ¬¡æŸå¤±

    # è®¡ç®—å¹³å‡è®­ç»ƒæŸå¤±
    avg_train_loss = train_loss / len(train_loader.dataset)
    train_losses.append(avg_train_loss)

    # -------------------------- éªŒè¯é˜¶æ®µ --------------------------
    model.eval()
    with torch.no_grad():  # ç¦ç”¨æ¢¯åº¦è®¡ç®—
        outputs = model(X_test_tensor)
        test_loss = criterion(outputs, y_test_tensor).item()
        test_losses.append(test_loss)

        # ä¿å­˜æœ€ä½³æ¨¡å‹ï¼ˆè®°å½•åç§»é‡å’Œæ ‡å‡†åŒ–å‚æ•°ï¼Œä¾¿äºåç»­é¢„æµ‹ï¼‰
        if test_loss < best_test_loss:
            best_test_loss = test_loss
            # ä¿å­˜æ¨¡å‹å‚æ•°
            torch.save(model.state_dict(), 'best_pole_residue_predictor.pth')
            # ä¿å­˜è®­ç»ƒå…³é”®ä¿¡æ¯
            best_model_info = {
                'epoch': epoch + 1,
                'train_loss': avg_train_loss,
                'test_loss': test_loss,
                'output_offset': output_offset,
                'input_cols': input_cols,
                'output_cols': output_cols,
                'scaler_X': {'mean': scaler_X.mean_.tolist(), 'std': scaler_X.scale_.tolist()},
                'scaler_y': {'mean': scaler_y.mean_.tolist(), 'std': scaler_y.scale_.tolist()},
                'batch_size': train_loader.batch_size,
                'lr': optimizer.param_groups[0]['lr']
            }
            np.save('best_model_info.npy', best_model_info)
            print(f"Epoch {epoch + 1:4d}: æµ‹è¯•æŸå¤±{test_loss:.6f}ï¼ˆå†å²æœ€ä½³ï¼‰â†’ ä¿å­˜æ¨¡å‹")

    # å­¦ä¹ ç‡è°ƒåº¦
    scheduler.step(test_loss)

    # æ¯10è½®æ‰“å°è®­ç»ƒæ—¥å¿—
    if (epoch + 1) % 10 == 0:
        current_lr = optimizer.param_groups[0]['lr']
        print(
            f"Epoch [{epoch + 1:4d}/{epochs}] | è®­ç»ƒæŸå¤±: {avg_train_loss:.6f} | æµ‹è¯•æŸå¤±: {test_loss:.6f} | å­¦ä¹ ç‡: {current_lr:.6f}")

# -------------------------- 6. åŠ è½½æœ€ä½³æ¨¡å‹å¹¶è¯„ä¼° --------------------------
print("\n" + "=" * 80)
print("è®­ç»ƒç»“æŸï¼ŒåŠ è½½æœ€ä½³æ¨¡å‹è¯„ä¼°")
print("=" * 80)

# åŠ è½½æ¨¡å‹ä¸å…³é”®ä¿¡æ¯
output_offset_loaded = output_offset
try:
    model.load_state_dict(torch.load('best_pole_residue_predictor.pth'))
    best_info = np.load('best_model_info.npy', allow_pickle=True).item()
    output_offset_loaded = best_info['output_offset']
    print(f"âœ… æˆåŠŸåŠ è½½æœ€ä½³æ¨¡å‹ï¼š")
    print(f"   - è®­ç»ƒè½®æ¬¡ï¼šEpoch {best_info['epoch']} | æœ€ä½³æµ‹è¯•æŸå¤±ï¼š{best_info['test_loss']:.6f}")
    print(f"   - å¤ç”¨æç‚¹åç§»é‡ï¼š{output_offset_loaded:.6f}")
except FileNotFoundError:
    print("âš ï¸ æœªæ‰¾åˆ°æœ€ä½³æ¨¡å‹æ–‡ä»¶ï¼Œä½¿ç”¨æœ€åä¸€è½®æ¨¡å‹è¯„ä¼°")
except Exception as e:
    print(f"âŒ åŠ è½½æ¨¡å‹å¤±è´¥ï¼š{str(e)}ï¼Œä½¿ç”¨å½“å‰åç§»é‡{output_offset_loaded:.6f}")
model.eval()

# é¢„æµ‹å¹¶åæ¨åŸå§‹å€¼ï¼ˆåˆ†ç¦»æç‚¹å’Œç•™æ•°ï¼Œä»…æç‚¹ååç§»ï¼‰
with torch.no_grad():
    # åæ ‡å‡†åŒ–ï¼šæ¢å¤åˆ°â€œåç§»æç‚¹+åŸå§‹ç•™æ•°â€å°ºåº¦
    y_pred_scaled = model(X_test_tensor)
    y_pred_final = scaler_y.inverse_transform(y_pred_scaled.numpy())
    y_true_final = scaler_y.inverse_transform(y_test_scaled)

    # åˆ†ç¦»æç‚¹å’Œç•™æ•°ï¼Œæç‚¹ååç§»ï¼ˆå‡åç§»é‡ï¼‰
    y_pred_poles = y_pred_final[:, :3] - output_offset_loaded  # åŸå§‹æç‚¹ï¼ˆè´Ÿï¼‰
    y_pred_residues = y_pred_final[:, 3:]  # åŸå§‹ç•™æ•°
    y_true_poles = y_true_final[:, :3] - output_offset_loaded  # çœŸå®æç‚¹
    y_true_residues = y_true_final[:, 3:]  # çœŸå®ç•™æ•°

# -------------------------- 7. è®¡ç®—è¯„ä¼°æŒ‡æ ‡ï¼ˆMAEï¼‰ --------------------------
# æç‚¹MAEï¼ˆä¸€ä¸€å¯¹åº”ï¼‰
mae_p1 = np.mean(np.abs(y_pred_poles[:, 0] - y_true_poles[:, 0]))
mae_p2 = np.mean(np.abs(y_pred_poles[:, 1] - y_true_poles[:, 1]))
mae_p3 = np.mean(np.abs(y_pred_poles[:, 2] - y_true_poles[:, 2]))
# ç•™æ•°MAEï¼ˆä¸€ä¸€å¯¹åº”ï¼‰
mae_r1 = np.mean(np.abs(y_pred_residues[:, 0] - y_true_residues[:, 0]))
mae_r2 = np.mean(np.abs(y_pred_residues[:, 1] - y_true_residues[:, 1]))
mae_r3 = np.mean(np.abs(y_pred_residues[:, 2] - y_true_residues[:, 2]))
# æ€»å¹³å‡MAE
total_mae = (mae_p1 + mae_p2 + mae_p3 + mae_r1 + mae_r2 + mae_r3) / 6

# æ‰“å°è¯„ä¼°ç»“æœ
print(f"\nğŸ“Š æ¨¡å‹è¯„ä¼°ç»“æœï¼ˆå¹³å‡ç»å¯¹è¯¯å·®MAEï¼‰ï¼š")
print("=" * 60)
print(f"{'ç±»å‹':<8} {'ç¬¬1ä¸ª':<12} {'ç¬¬2ä¸ª':<12} {'ç¬¬3ä¸ª':<12} {'å­é¡¹å¹³å‡':<12}")
print("=" * 60)
print(f"{'æç‚¹':<8} {mae_p1:.4f}       {mae_p2:.4f}       {mae_p3:.4f}       {(mae_p1 + mae_p2 + mae_p3) / 3:.4f}")
print(f"{'ç•™æ•°':<8} {mae_r1:.4f}       {mae_r2:.4f}       {mae_r3:.4f}       {(mae_r1 + mae_r2 + mae_r3) / 3:.4f}")
print("=" * 60)
print(f"{'æ€»å¹³å‡':<8} {'':<12} {'':<12} {'':<12} {total_mae:.4f}")

# -------------------------- 8. å¯è§†åŒ–ç»“æœ --------------------------
# 8.1 è®­ç»ƒ/æµ‹è¯•æŸå¤±æ›²çº¿
plt.figure(figsize=(10, 6))
plt.plot(range(1, epochs + 1), train_losses, color='#2E86AB', linewidth=1.5, label='è®­ç»ƒæŸå¤±')
plt.plot(range(1, epochs + 1), test_losses, color='#FF6B6B', linewidth=1.5, label='æµ‹è¯•æŸå¤±')
# æ ‡æ³¨æœ€ä½³æ¨¡å‹è½®æ¬¡
if 'best_info' in locals():
    plt.scatter(best_info['epoch'], best_info['test_loss'], color='red', s=60,
                label=f'æœ€ä½³æ¨¡å‹ï¼ˆEpoch{best_info["epoch"]}ï¼‰', zorder=5)
plt.xlabel('è®­ç»ƒè½®æ¬¡ï¼ˆEpochï¼‰', fontsize=12)
plt.ylabel('æŸå¤±å€¼ï¼ˆMSEï¼‰', fontsize=12)
plt.title('è®­ç»ƒä¸æµ‹è¯•æŸå¤±æ›²çº¿', fontsize=14, pad=15)
plt.legend(fontsize=10)
plt.grid(True, linestyle='--', alpha=0.7)
plt.tight_layout()
plt.savefig('loss_curve.png', dpi=300, bbox_inches='tight')
plt.close()
print(f"\nğŸ“ˆ æŸå¤±æ›²çº¿å·²ä¿å­˜ä¸ºï¼šloss_curve.png")

# 8.2 æç‚¹é¢„æµ‹å¯¹æ¯”å›¾ï¼ˆå‰50ä¸ªæ ·æœ¬ï¼Œ3ä¸ªå­å›¾ï¼‰
sample_num = min(50, len(y_true_poles))
sample_indices = np.arange(sample_num)
fig, axes = plt.subplots(3, 1, figsize=(12, 15), sharex=True)

for i, ax in enumerate(axes):
    ax.plot(sample_indices, y_true_poles[sample_indices, i],
            color='#2E86AB', linewidth=2, label='çœŸå®æç‚¹')
    ax.plot(sample_indices, y_pred_poles[sample_indices, i],
            color='#FF6B6B', linewidth=1.5, linestyle='--', label='é¢„æµ‹æç‚¹')
    ax.set_title(f'æç‚¹{i+1}é¢„æµ‹å€¼ä¸çœŸå®å€¼å¯¹æ¯”ï¼ˆå‰{sample_num}ä¸ªæ ·æœ¬ï¼‰', fontsize=13, pad=12)
    ax.set_ylabel('æç‚¹å€¼ï¼ˆè´Ÿå®æ•°ï¼‰', fontsize=11)
    ax.legend(fontsize=10)
    ax.grid(True, linestyle='--', alpha=0.3)

axes[-1].set_xlabel('æ ·æœ¬ç´¢å¼•', fontsize=11)
plt.tight_layout()
plt.savefig('pole_prediction_comparison.png', dpi=300, bbox_inches='tight')
plt.close()
print(f"ğŸ“Š æç‚¹é¢„æµ‹å¯¹æ¯”å›¾å·²ä¿å­˜ä¸ºï¼špole_prediction_comparison.png")

# 8.3 ç•™æ•°é¢„æµ‹å¯¹æ¯”å›¾ï¼ˆå‰50ä¸ªæ ·æœ¬ï¼Œ3ä¸ªå­å›¾ï¼‰
fig, axes = plt.subplots(3, 1, figsize=(12, 15), sharex=True)
for i, ax in enumerate(axes):
    ax.plot(sample_indices, y_true_residues[sample_indices, i],
            color='#2E86AB', linewidth=2, label='çœŸå®ç•™æ•°')
    ax.plot(sample_indices, y_pred_residues[sample_indices, i],
            color='#FF6B6B', linewidth=1.5, linestyle='--', label='é¢„æµ‹ç•™æ•°')
    ax.set_title(f'ç•™æ•°{i+1}é¢„æµ‹å€¼ä¸çœŸå®å€¼å¯¹æ¯”ï¼ˆå‰{sample_num}ä¸ªæ ·æœ¬ï¼‰', fontsize=13, pad=12)
    ax.set_ylabel('ç•™æ•°å€¼ï¼ˆå®æ•°ï¼‰', fontsize=11)
    ax.legend(fontsize=10)
    ax.grid(True, linestyle='--', alpha=0.3)

axes[-1].set_xlabel('æ ·æœ¬ç´¢å¼•', fontsize=11)
plt.tight_layout()
plt.savefig('residue_prediction_comparison.png', dpi=300, bbox_inches='tight')
plt.close()
print(f"ğŸ“Š ç•™æ•°é¢„æµ‹å¯¹æ¯”å›¾å·²ä¿å­˜ä¸ºï¼šresidue_prediction_comparison.png")

# -------------------------- 9. æ‰“å°å‰10æ¡é¢„æµ‹ç»“æœæ˜ç»† --------------------------
print("\n" + "=" * 120)
print("å‰10æ¡æ ·æœ¬é¢„æµ‹ç»“æœæ˜ç»†ï¼ˆæç‚¹-ç•™æ•°ä¸€ä¸€å¯¹åº”ï¼‰")
print("=" * 120)
print(
    f"{'æ ·æœ¬':<6} {'çœŸå®æç‚¹1':<12} {'é¢„æµ‹æç‚¹1':<12} {'çœŸå®æç‚¹2':<12} {'é¢„æµ‹æç‚¹2':<12} "
    f"{'çœŸå®æç‚¹3':<12} {'é¢„æµ‹æç‚¹3':<12} {'çœŸå®ç•™æ•°1':<12} {'é¢„æµ‹ç•™æ•°1':<12} "
    f"{'çœŸå®ç•™æ•°2':<12} {'é¢„æµ‹ç•™æ•°2':<12} {'çœŸå®ç•™æ•°3':<12} {'é¢„æµ‹ç•™æ•°3':<12}"
)
print("-" * 120)
for i in range(min(10, len(y_pred_poles))):
    print(
        f"{i:<6} {y_true_poles[i,0]:<12.4f} {y_pred_poles[i,0]:<12.4f} "
        f"{y_true_poles[i,1]:<12.4f} {y_pred_poles[i,1]:<12.4f} "
        f"{y_true_poles[i,2]:<12.4f} {y_pred_poles[i,2]:<12.4f} "
        f"{y_true_residues[i,0]:<12.4f} {y_pred_residues[i,0]:<12.4f} "
        f"{y_true_residues[i,1]:<12.4f} {y_pred_residues[i,1]:<12.4f} "
        f"{y_true_residues[i,2]:<12.4f} {y_pred_residues[i,2]:<12.4f}"
    )

print("\n" + "=" * 80)
print("æ‰€æœ‰æ–‡ä»¶å·²ä¿å­˜è‡³å½“å‰ç›®å½•ï¼š")
print("1. best_pole_residue_predictor.pth â†’ æœ€ä½³æ¨¡å‹å‚æ•°")
print("2. best_model_info.npy â†’ è®­ç»ƒä¿¡æ¯ï¼ˆå«åç§»é‡+æ ‡å‡†åŒ–å‚æ•°ï¼‰")
print("3. loss_curve.png â†’ è®­ç»ƒ/æµ‹è¯•æŸå¤±æ›²çº¿")
print("4. pole_prediction_comparison.png â†’ æç‚¹é¢„æµ‹å¯¹æ¯”å›¾")
print("5. residue_prediction_comparison.png â†’ ç•™æ•°é¢„æµ‹å¯¹æ¯”å›¾")
print("=" * 80)